{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OqNFWx7UDlR6"
      },
      "outputs": [],
      "source": [
        "#@title # Step 1: Setup\n",
        "\n",
        "import os\n",
        "os.environ['LANG'] = 'en_US.UTF-8'\n",
        "os.environ['LC_ALL'] = 'en_US.UTF-8'\n",
        "import locale\n",
        "locale.getpreferredencoding = lambda: \"UTF-8\"\n",
        "\n",
        "%cd /content\n",
        "if not os.path.isdir('Thin-Plate-Spline-Motion-Model'):\n",
        "    !git clone https://github.com/gee666/Thin-Plate-Spline-Motion-Model.git\n",
        "%cd Thin-Plate-Spline-Motion-Model"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title # Step 2: Load models\n",
        "#@markdown ## uncomment the models you want to use\n",
        "\n",
        "!mkdir checkpoints\n",
        "!pip3 install wldhx.yadisk-direct\n",
        "\n",
        "!curl -L $(yadisk-direct https://disk.yandex.com/d/i08z-kCuDGLuYA) -o checkpoints/vox.pth.tar\n",
        "#!curl -L $(yadisk-direct https://disk.yandex.com/d/vk5dirE6KNvEXQ) -o checkpoints/taichi.pth.tar\n",
        "#!curl -L $(yadisk-direct https://disk.yandex.com/d/IVtro0k2MVHSvQ) -o checkpoints/mgif.pth.tar\n",
        "#!curl -L $(yadisk-direct https://disk.yandex.com/d/B3ipFzpmkB1HIA) -o checkpoints/ted.pth.tar\n",
        "\n",
        "# different source\n",
        "#!curl -L $(yadisk-direct https://disk.yandex.ru/d/YbOdosYEwYY_SA) -o checkpoints/vox.pth.tar\n",
        "#!curl -L $(yadisk-direct https://disk.yandex.ru/d/6eKgFjCUA-7k2w) -o checkpoints/taichi.pth.tar\n",
        "#!curl -L $(yadisk-direct https://disk.yandex.ru/d/PRSRPrSgIExosw) -o checkpoints/mgif.pth.tar\n",
        "#!curl -L $(yadisk-direct https://disk.yandex.ru/d/YbOdosYEwYY_SA) -o checkpoints/ted.pth.tar"
      ],
      "metadata": {
        "id": "X-Bx4QT1UOod"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title # Step 3: Settings\n",
        "#@markdown ##### Import your driving video and/or image before filling in the form\n",
        "#@markdown ##### For best result video and image should be squared 256x256 px\n",
        "\n",
        "\n",
        "import torch\n",
        "import importlib.util\n",
        "import os\n",
        "\n",
        "testmode = False # for testing with little amount of frames\n",
        "max_frames_in_testmode = 16\n",
        "\n",
        "current_directory = os.getcwd()\n",
        "\n",
        "device = torch.device('cuda:0')\n",
        "dataset_name = 'vox' #@param {type:\"string\"} ['vox', 'taichi', 'ted', 'mgif']\n",
        "\n",
        "source_image_path = '/content/Thin-Plate-Spline-Motion-Model/assets/source.png' #@param {type:\"string\"}\n",
        "source_image_path = os.path.join(current_directory, source_image_path)\n",
        "source_image_path = os.path.relpath(source_image_path, current_directory)\n",
        "\n",
        "driving_video_path = '/content/Thin-Plate-Spline-Motion-Model/assets/driving.mp4' #@param {type:\"string\"}\n",
        "driving_video_path = os.path.join(current_directory, driving_video_path)\n",
        "driving_video_path = os.path.relpath(driving_video_path, current_directory)\n",
        "\n",
        "output_frames_directory = './output_frames/'\n",
        "output_video_chunks = './video_chunks'\n",
        "output_video_path = './generated.mp4'\n",
        "predict_mode = 'relative' #@param {type:\"string\"}  ['standard', 'relative', 'avd']\n",
        "\n",
        "#@markdown ##### Max batch size will depend on your memory and video size\n",
        "max_batch_size = 2000 #@param { type:\"number\" }\n",
        "\n",
        "fps = 24 # later this value will be corrected\n",
        "if testmode:\n",
        "  max_batch_size = max_frames_in_testmode\n",
        "\n",
        "find_best_frame = False\n",
        "# for relative using find best frame, which can give beeter results\n",
        "if predict_mode == 'relative':\n",
        "  find_best_frame = True\n",
        "  if importlib.util.find_spec('face_alignment') is None:\n",
        "      !pip install face-alignment\n",
        "\n",
        "# for vox, taichi and mgif, the resolution is 256*256\n",
        "pixel = 256\n",
        "# for ted, the resolution is 384*384\n",
        "if(dataset_name == 'ted'):\n",
        "    pixel = 384\n",
        "\n",
        "config_path = f'config/{dataset_name}-{pixel}.yaml'\n",
        "checkpoint_path = f'checkpoints/{dataset_name}.pth.tar'"
      ],
      "metadata": {
        "id": "9x_r_ztKECeB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title # Step 4: Define functions\n",
        "try:\n",
        "  import imageio\n",
        "  import imageio_ffmpeg\n",
        "except:\n",
        "  !pip install imageio_ffmpeg\n",
        "  import imageio\n",
        "  import imageio_ffmpeg\n",
        "import numpy as np\n",
        "from skimage.transform import resize\n",
        "import warnings\n",
        "import os\n",
        "from tqdm.auto import tqdm\n",
        "from skimage import img_as_ubyte\n",
        "import shutil\n",
        "import gc\n",
        "import sys\n",
        "\n",
        "from demo import make_animation\n",
        "from demo import load_checkpoints\n",
        "\n",
        "\n",
        "# Define ensure and clean directory function\n",
        "def prepare_directory(directory_path, clean=True):\n",
        "    \"\"\"\n",
        "    Ensure the directory exists and is empty.\n",
        "\n",
        "    If the directory exists, clear its contents. If not, create the directory.\n",
        "\n",
        "    Parameters:\n",
        "    - directory_path: The path to the directory to prepare.\n",
        "    \"\"\"\n",
        "    if not os.path.exists(directory_path):\n",
        "        # Directory does not exist, so create it\n",
        "        os.makedirs(directory_path)\n",
        "    elif clean:\n",
        "        # Directory exists, remove any existing files and directories within it\n",
        "        for filename in os.listdir(directory_path):\n",
        "            file_path = os.path.join(directory_path, filename)\n",
        "            try:\n",
        "                if os.path.isfile(file_path) or os.path.islink(file_path):\n",
        "                    os.unlink(file_path)\n",
        "                elif os.path.isdir(file_path):\n",
        "                    shutil.rmtree(file_path)\n",
        "            except Exception as e:\n",
        "                print('Failed to delete %s. Reason: %s' % (file_path, e))\n",
        "\n",
        "\n",
        "def memory_usage():\n",
        "  !echo -n \"Available Memory: \" && cat /proc/meminfo | grep 'MemAvailable' | awk '{print $2/1024 \" MB\"}'\n",
        "\n",
        "\n",
        "def animate(source_image, driving_video):\n",
        "  inpainting, kp_detector, dense_motion_network, avd_network = load_checkpoints(config_path = config_path, checkpoint_path = checkpoint_path, device = device)\n",
        "  if predict_mode=='relative' and find_best_frame:\n",
        "      from demo import find_best_frame as _find\n",
        "      i = _find(source_image, driving_video, device.type=='cpu')\n",
        "      print (\"Best frame: \" + str(i))\n",
        "      driving_forward = driving_video[i:]\n",
        "      driving_backward = driving_video[:(i+1)][::-1]\n",
        "      predictions_forward = make_animation(source_image, driving_forward, inpainting, kp_detector, dense_motion_network, avd_network, device = device, mode = predict_mode)\n",
        "      predictions_backward = make_animation(source_image, driving_backward, inpainting, kp_detector, dense_motion_network, avd_network, device = device, mode = predict_mode)\n",
        "      predictions = predictions_backward[::-1] + predictions_forward[1:]\n",
        "  else:\n",
        "      predictions = make_animation(source_image, driving_video, inpainting, kp_detector, dense_motion_network, avd_network, device = device, mode = predict_mode)\n",
        "  return predictions\n",
        "\n",
        "def process_batch(source_image, reader, total_frames_processed):\n",
        "    driving_video = []\n",
        "\n",
        "    for frame in tqdm(reader, total=reader.count_frames(), desc=\"resizing frames: \"):\n",
        "        frame = resize(frame, (pixel, pixel))[..., :3]\n",
        "        driving_video.append(frame)\n",
        "\n",
        "    memory_usage()\n",
        "    print(\"animating frames...\")\n",
        "    predictions = animate(source_image, driving_video)\n",
        "    memory_usage()\n",
        "\n",
        "    del driving_video\n",
        "    gc.collect()\n",
        "\n",
        "    print(f\"saving the batch frames...\")\n",
        "    # Save the resulting frames into the directory \"output_frames_directory\"\n",
        "    for idx, frame in enumerate(predictions):\n",
        "      total_frames_processed += 1\n",
        "      imageio.imsave(f'{output_frames_directory}/frame_{total_frames_processed:04d}.png', img_as_ubyte(frame))\n",
        "    print(f\"...batch saved\")\n",
        "\n",
        "    del predictions\n",
        "    gc.collect()\n",
        "\n",
        "    return total_frames_processed\n",
        "\n",
        "\n",
        "def process_video(source_image):\n",
        "    # List all video part files\n",
        "    video_parts = sorted([file for file in os.listdir(output_video_chunks) if file.endswith('.mp4')])\n",
        "    total_frames_processed = 0\n",
        "\n",
        "    for video_part in video_parts:\n",
        "        video_part_path = os.path.join(output_video_chunks, video_part)\n",
        "        print(f\"Processing video part: {video_part_path}\")\n",
        "\n",
        "        # read the current video part\n",
        "        reader = imageio.get_reader(video_part_path)\n",
        "        fps = reader.get_meta_data()['fps']\n",
        "\n",
        "        # Process the entire part as a single batch\n",
        "        total_frames_processed = process_batch(source_image, reader, total_frames_processed)\n",
        "\n",
        "        reader.close()\n",
        "        del reader\n",
        "        gc.collect()\n",
        "\n",
        "    print(\"_______________________\")\n",
        "    print(f\"Total frames processed: {total_frames_processed}\")\n",
        "    print(\"_______________________\")\n",
        "    memory_usage()\n",
        "\n",
        "\n",
        "\n",
        "def split_video():\n",
        "  # Initialize the video reader\n",
        "  reader = imageio.get_reader(driving_video_path)\n",
        "  global fps\n",
        "  fps=reader.get_meta_data()['fps']\n",
        "\n",
        "  print(\"_______________________\")\n",
        "  print(f\"Total frames count {reader.count_frames()}\")\n",
        "  print(f\"Original fps {fps}\")\n",
        "  print(\"_______________________\")\n",
        "\n",
        "  # Initialize variables\n",
        "  part_number = 1\n",
        "  frame_count = 0\n",
        "  writer = None\n",
        "\n",
        "  # Iterate over frames\n",
        "  for i, frame in enumerate(reader):\n",
        "      # Start a new part if frame_count reached frames_per_part\n",
        "      if frame_count == 0:\n",
        "          if writer:\n",
        "              writer.close()\n",
        "          writer = imageio.get_writer(f'{output_video_chunks}/part_{part_number:02d}.mp4', fps=fps)\n",
        "          part_number += 1\n",
        "\n",
        "      # Write the current frame\n",
        "      writer.append_data(frame)\n",
        "      frame_count += 1\n",
        "\n",
        "      # Reset frame count if it reaches the limit\n",
        "      if frame_count == max_batch_size:\n",
        "          frame_count = 0\n",
        "\n",
        "      # Test mode condition\n",
        "      if testmode and part_number > 1:\n",
        "          break\n",
        "\n",
        "  # Close the last writer\n",
        "  if writer:\n",
        "      writer.close()\n",
        "\n",
        "  del reader, writer\n",
        "  gc.collect()"
      ],
      "metadata": {
        "id": "rA5u3wZCCoBg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title # Step 5: Here the magic happens\n",
        "\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "prepare_directory(output_frames_directory)\n",
        "prepare_directory(output_video_chunks)\n",
        "\n",
        "memory_usage()\n",
        "\n",
        "# read the image\n",
        "print(\"Preparing source image...\")\n",
        "source_image = imageio.imread(source_image_path)\n",
        "# Ensure source_image has three channels\n",
        "source_image = resize(source_image, (pixel, pixel))[..., :3]\n",
        "memory_usage()\n",
        "\n",
        "print(\"Splitting the video on chuncs...\")\n",
        "split_video()\n",
        "\n",
        "memory_usage()\n",
        "process_video(source_image)\n",
        "gc.collect()\n",
        "\n",
        "# When all frames are done, combine all the output_frames into the resulting video\n",
        "print(f\"Saving video to {output_video_path}...\")\n",
        "output_frames = sorted(os.listdir(output_frames_directory), key=lambda x: int(x.split('_')[1].split('.')[0]))\n",
        "with imageio.get_writer(output_video_path, fps=fps) as writer:\n",
        "    for frame_filename in output_frames:\n",
        "        frame_path = os.path.join(output_frames_directory, frame_filename)\n",
        "        frame = imageio.imread(frame_path)\n",
        "        writer.append_data(frame)\n",
        "print(\"done!\")\n",
        "\n",
        "del output_frames, source_image\n",
        "gc.collect()\n",
        "memory_usage()"
      ],
      "metadata": {
        "id": "fZeqlpzSLoKg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title # Commit suicide\n",
        "import os\n",
        "os.kill(os.getpid(), 9)"
      ],
      "metadata": {
        "id": "K8CkfuG6kmXX"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
